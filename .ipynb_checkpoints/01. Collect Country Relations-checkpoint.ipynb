{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0028e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lawli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lawli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from entity_extraction import get_cameo_mappings, parse_sentence, tokenize, format_parsed_str, send_to_petr\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45f1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204450, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               link  \\\n",
       "0      0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1      1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2      2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3      3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4      4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_json(\"News_Category_Dataset_v3.json\", lines= \"True\")\n",
    "news = news[news['category'] != \"SPORTS\"]\n",
    "news.reset_index(inplace=True)\n",
    "print(news.shape)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507e23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config.ini\"\n",
    "map_dict = get_cameo_mappings(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f97efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_information(df):\n",
    "    story_id = str(df[0])\n",
    "    text = df[2] + \". \" +  df[4]\n",
    "    date = \"202209230908\"\n",
    "\n",
    "    event_dict = {story_id: {}}\n",
    "    event_dict[story_id][\"sents\"] = {}\n",
    "    event_dict[story_id][\"meta\"] = {}\n",
    "    event_dict[story_id][\"meta\"][\"date\"] = date\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    for i, _ in enumerate(sentences):\n",
    "        sent = sentences[i]\n",
    "        event_dict[story_id][\"sents\"][str(i)] = {}\n",
    "        event_dict[story_id][\"sents\"][str(i)][\"content\"] = ' '.join(tokenize(sent))\n",
    "        corenlp_parsed = parse_sentence(sent)\n",
    "        event_dict[story_id][\"sents\"][str(i)][\"parsed\"] = format_parsed_str(corenlp_parsed)\n",
    "    event_updated = send_to_petr(event_dict)\n",
    "    event_updated[story_id][\"meta\"][\"date\"] = df[6]\n",
    "    return event_updated\n",
    "\n",
    "def resolve_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return [a for i in x for a in resolve_list(i)]\n",
    "    else:\n",
    "        return [str(x).strip().lower()]\n",
    "\n",
    "def resolve_list_join(x):\n",
    "\n",
    "    if isinstance(x, list):\n",
    "        if any(isinstance(item, list) for item in x):\n",
    "            return [a for i in x for a in resolve_list(i)]\n",
    "        else:\n",
    "            return [\" \".join(x).strip().lower()]\n",
    "    else:\n",
    "        return [x.strip().lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164a4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>event_code</th>\n",
       "      <th>goldstein_score</th>\n",
       "      <th>nouns</th>\n",
       "      <th>actortext</th>\n",
       "      <th>actorroot</th>\n",
       "      <th>eventtext</th>\n",
       "      <th>issues</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [link, headline, category, short_description, authors, date, actor1, actor2, event_code, goldstein_score, nouns, actortext, actorroot, eventtext, issues, events]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_names = ['link', 'headline', 'category', 'short_description', 'authors', 'date',\n",
    "              'actor1', 'actor2', 'event_code', 'goldstein_score', 'nouns', 'actortext', 'actorroot',\n",
    "              'eventtext', 'issues', 'events']\n",
    "\n",
    "country_relations = pd.DataFrame(columns = field_names)\n",
    "country_relations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f7c2893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:05,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203200 to 203300 out of 204450 total rows\n",
      "Saving 203200 to 203300 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [03:39,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203300 to 203400 out of 204450 total rows\n",
      "Saving 203300 to 203400 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [05:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203400 to 203500 out of 204450 total rows\n",
      "Saving 203400 to 203500 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [06:50,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203500 to 203600 out of 204450 total rows\n",
      "Saving 203500 to 203600 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [08:44,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203600 to 203700 out of 204450 total rows\n",
      "Saving 203600 to 203700 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [10:27,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203700 to 203800 out of 204450 total rows\n",
      "Saving 203700 to 203800 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [12:13,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203800 to 203900 out of 204450 total rows\n",
      "Saving 203800 to 203900 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [13:51,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 203900 to 204000 out of 204450 total rows\n",
      "Saving 203900 to 204000 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [15:42,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 204000 to 204100 out of 204450 total rows\n",
      "Saving 204000 to 204100 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [17:30,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 204100 to 204200 out of 204450 total rows\n",
      "Saving 204100 to 204200 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [19:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 204200 to 204300 out of 204450 total rows\n",
      "Saving 204200 to 204300 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [20:59,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 204300 to 204400 out of 204450 total rows\n",
      "Saving 204300 to 204400 to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1250it [21:51,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "start = 203200  \n",
    "interval = 100\n",
    "end = start + interval\n",
    "i = start\n",
    "\n",
    "drop_rows = [28473, 65613, 73486, 119174, 124136, 125657, 128507, 128562, 177432, 182749, 206601]\n",
    "news_resume = news.iloc[start : ][:]\n",
    "drop_index = news_resume[news_resume['index'].isin(drop_rows)].index\n",
    "news_resume.drop(drop_index, inplace=True)\n",
    "news_resume.head(45)\n",
    "\n",
    "total = news.shape[0]\n",
    "\n",
    "for row in tqdm(news_resume.iterrows()):\n",
    "\n",
    "    if i >= start and i <end:\n",
    "        \n",
    "        info = get_entity_information(row[1]) \n",
    "        story_id = str(list(info.keys())[0])\n",
    "\n",
    "        if info[story_id]['sents']:\n",
    "            for sent in info[story_id]['sents']:\n",
    "\n",
    "                if 'events' in info[story_id]['sents'][sent]:\n",
    "\n",
    "                    row_dict = { column_name : None for column_name in field_names }\n",
    "\n",
    "                    row_dict['events'] = resolve_list(info[story_id]['sents'][sent]['events'])\n",
    "                    row_dict['link'] = row[1][1]\n",
    "                    row_dict['headline'] = row[1][2]\n",
    "                    row_dict['short_description'] = row[1][4]\n",
    "                    row_dict['authors'] = row[1][5]\n",
    "                    row_dict['date'] = str(row[1][6])\n",
    "                    row_dict['category'] = row[1][3]\n",
    "                    row_dict['actor1'] = row_dict['events'][0]\n",
    "                    row_dict['actor2'] = row_dict['events'][1]\n",
    "                    row_dict['event_code'] = row_dict['events'][2]\n",
    "                    try:\n",
    "                        row_dict['goldstein_score'] = map_dict[row_dict['event_code']]\n",
    "                    except:\n",
    "                        print(\"skipping..\")\n",
    "                    row_dict['nouns'] = resolve_list_join(info[story_id]['sents'][sent]['meta']['nouns'])\n",
    "                    row_dict['actortext'] = resolve_list(info[story_id]['sents'][sent]['meta']['actortext'])\n",
    "                    row_dict['actorroot'] = resolve_list(info[story_id]['sents'][sent]['meta']['actorroot'])\n",
    "                    row_dict['eventtext'] = resolve_list(info[story_id]['sents'][sent]['meta']['eventtext'])\n",
    "\n",
    "                    if 'issues' in info[story_id]['sents'][sent]:\n",
    "                        row_dict['issues'] = resolve_list(info[story_id]['sents'][sent]['issues'])\n",
    "                    \n",
    "                    rows.append(row_dict)\n",
    " \n",
    "    else:\n",
    "        print(f\"Processing rows {start} to {end} out of {total} total rows\")\n",
    "        print(f\"Saving {start} to {end} to disk...\")\n",
    "        country_relations_dict = pd.DataFrame.from_dict(rows)\n",
    "        country_relations_dict.to_json(f\"json_dir/country_relations_{start}_{end}.json\", indent = 2)\n",
    "        rows = []\n",
    "        \n",
    "        start = end\n",
    "        end = end + interval\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "    if i > total:\n",
    "        break\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "791568d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>event_code</th>\n",
       "      <th>goldstein_score</th>\n",
       "      <th>nouns</th>\n",
       "      <th>actortext</th>\n",
       "      <th>actorroot</th>\n",
       "      <th>eventtext</th>\n",
       "      <th>issues</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/reporter-gets-a...</td>\n",
       "      <td>Reporter Gets Adorable Surprise From Her Boyfr...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>\"Who's that behind you?\" an anchor for New Yor...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-22 00:00:00</td>\n",
       "      <td>usa</td>\n",
       "      <td>---med</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>[new york, usa, united, states, of, america, j...</td>\n",
       "      <td>[new york, journalist]</td>\n",
       "      <td>[united states of america, ---]</td>\n",
       "      <td>[asked]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[usa, ---med, 020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/puerto-rico-wat...</td>\n",
       "      <td>Puerto Ricans Desperate For Water After Hurric...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>More than half a million people remained witho...</td>\n",
       "      <td>DÁNICA COTO, AP</td>\n",
       "      <td>2022-09-22 00:00:00</td>\n",
       "      <td>---ppl</td>\n",
       "      <td>usa</td>\n",
       "      <td>180</td>\n",
       "      <td>-9</td>\n",
       "      <td>[people, ~ppl, ~, u.s., usa, united, states, o...</td>\n",
       "      <td>[people, u.s.]</td>\n",
       "      <td>[---, united states of america]</td>\n",
       "      <td>[remained ... lashed]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[---ppl, usa, 180]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/russian-control...</td>\n",
       "      <td>4 Russian-Controlled Ukrainian Regions Schedul...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>The concerted and quickening Kremlin-backed ef...</td>\n",
       "      <td>Jon Gambrell, AP</td>\n",
       "      <td>2022-09-20 00:00:00</td>\n",
       "      <td>ukr</td>\n",
       "      <td>rus</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>[ukrainian, ukr, ukraine, russia, rus, russian...</td>\n",
       "      <td>[ukrainian, russia]</td>\n",
       "      <td>[ukraine, russian federation]</td>\n",
       "      <td>[schedule ... join]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ukr, rus, 040]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/reporter-gets-a...   \n",
       "1  https://www.huffpost.com/entry/puerto-rico-wat...   \n",
       "2  https://www.huffpost.com/entry/russian-control...   \n",
       "\n",
       "                                            headline    category  \\\n",
       "0  Reporter Gets Adorable Surprise From Her Boyfr...   U.S. NEWS   \n",
       "1  Puerto Ricans Desperate For Water After Hurric...  WORLD NEWS   \n",
       "2  4 Russian-Controlled Ukrainian Regions Schedul...  WORLD NEWS   \n",
       "\n",
       "                                   short_description           authors  \\\n",
       "0  \"Who's that behind you?\" an anchor for New Yor...     Elyse Wanshel   \n",
       "1  More than half a million people remained witho...   DÁNICA COTO, AP   \n",
       "2  The concerted and quickening Kremlin-backed ef...  Jon Gambrell, AP   \n",
       "\n",
       "                  date  actor1  actor2 event_code goldstein_score  \\\n",
       "0  2022-09-22 00:00:00     usa  ---med         20               3   \n",
       "1  2022-09-22 00:00:00  ---ppl     usa        180              -9   \n",
       "2  2022-09-20 00:00:00     ukr     rus         40               1   \n",
       "\n",
       "                                               nouns               actortext  \\\n",
       "0  [new york, usa, united, states, of, america, j...  [new york, journalist]   \n",
       "1  [people, ~ppl, ~, u.s., usa, united, states, o...          [people, u.s.]   \n",
       "2  [ukrainian, ukr, ukraine, russia, rus, russian...     [ukrainian, russia]   \n",
       "\n",
       "                         actorroot              eventtext issues  \\\n",
       "0  [united states of america, ---]                [asked]    NaN   \n",
       "1  [---, united states of america]  [remained ... lashed]    NaN   \n",
       "2    [ukraine, russian federation]    [schedule ... join]    NaN   \n",
       "\n",
       "               events  \n",
       "0  [usa, ---med, 020]  \n",
       "1  [---ppl, usa, 180]  \n",
       "2     [ukr, rus, 040]  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "json_dir = 'json_dir'\n",
    "\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "country_relations = pd.DataFrame(columns = field_names)\n",
    "\n",
    "for file in file_list:\n",
    "    temp_df = pd.read_json(file)\n",
    "    country_relations = pd.concat([country_relations, temp_df], axis =0)\n",
    "\n",
    "country_relations.reset_index(inplace=True)\n",
    "country_relations.drop(['index'], axis = 1, inplace =True)\n",
    "print(country_relations.shape)\n",
    "country_relations.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3907f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final processed file to disk\n",
    "country_relations.to_json(f\"country_relations_final.json\", indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1891ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new york'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reload final file\n",
    "country_relations_final = pd.read_json(\"country_relations_final.json\")\n",
    "country_relations_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a03f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
